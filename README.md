<img src="https://github.com/kunishou/Japanese-Alpaca-LoRA/blob/main/image/top.png" alt="alpaca">

# ğŸ¦™ğŸŒ²ğŸ¤ğŸŒ¸ Japanese-Alpaca-LoRA ğŸŒ¸
Alpaca-LoRA is a {model_param}-parameter LLaMA model finetuned to follow instructions. It is trained on the [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) dataset

æ—¥æœ¬èªã«ç¿»è¨³ã—ãŸStanford Alpacaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦LLaMAã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ä½œæˆã—ãŸLow-Rank Adapterã®ãƒªãƒ³ã‚¯ã¨Generateã£ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

### Japanese-Alpaca-LoRA-7b DEMOãƒšãƒ¼ã‚¸(æœŸé–“é™å®š 2023/3/23 12:00 ï½ 2023/3/24 12:00)  
https://huggingface.co/spaces/kunishou/Japanese-Alapaca-LoRA-7b-DEMO

Instruct : æŒ‡ç¤ºã‚’å…¥åŠ›
Input : ä»˜å±æƒ…å ±ã‚’å…¥åŠ›
Temparature : ç”Ÿæˆã™ã‚‹å›ç­”ã®å¤šæ§˜æ€§åº¦åˆã„  
Beams : ç”Ÿæˆã™ã‚‹å›ç­”ã®å€™è£œæ•°  
Max_tokens : ç”Ÿæˆã™ã‚‹å›ç­”ã®é•·ã•  

å…¥åŠ›ä¾‹ï¼š  
instruct : æ¬¡ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ä¸‹ã•ã„ã€‚  
input : ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ãŸã¯æ·±å±¤å­¦ç¿’ã¨ã¯ã€å¯¾è±¡ã®å…¨ä½“åƒã‹ã‚‰ç´°éƒ¨ã¾ã§ã®å„ã€…ã®ç²’åº¦ã®æ¦‚å¿µã‚’éšå±¤æ§‹é€ ã¨ã—ã¦é–¢é€£ã•ã›ã¦å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã®ã“ã¨ã§ã‚ã‚‹ã€‚ã‚³ãƒ¼ã‚»ãƒ©ã®å…±åŒå‰µæ¥­è€…ã§ã‚ã‚‹ã‚¢ãƒ³ãƒ‰ãƒªãƒ¥ãƒ¼ãƒ»ãƒ³ã«ã‚ˆã‚Œã°ã€ã€Œäººå·¥çŸ¥èƒ½ã¸ã®ç¬¬ä¸€æ­©ã€ã¨ã„ã†èªè­˜ã¯æ­£ã—ã„ã®ã ã¨ã„ã†ã€‚

### Try the pretrainde model using google colab
Google Colabã§å®Ÿè¡Œã—ãŸã„å ´åˆã¯ä»¥ä¸‹ã‚ˆã‚Šï¼ˆ30Bãªã©ã®å¤§ãã„ãƒ¢ãƒ‡ãƒ«ã¯Proãƒ—ãƒ©ãƒ³ä»¥ä¸Šã§A100ã‚’ä½¿ã‚ãªã„ã¨å‹•ã‹ãªã„ã‹ã‚‚ï¼‰

<a href="https://colab.research.google.com/github/kunishou/Japanese-Alpaca-LoRA/blob/main/generate_colb.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

### LoRA on Hugging Face
Japanese-Alpaca-LoRA 7b, 13B, 30B (65B Coming Soon!)
https://huggingface.co/kunishou

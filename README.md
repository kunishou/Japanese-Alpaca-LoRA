<img src="https://github.com/kunishou/Japanese-Alpaca-LoRA/blob/main/image/top.png" alt="alpaca">

# 🦙🌲🤏🌸 Japanese-Alpaca-LoRA 🌸
Alpaca-LoRA is a {model_param}-parameter LLaMA model finetuned to follow instructions. It is trained on the [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) dataset

日本語に翻訳したStanford Alpacaのデータセットを用いてLLaMAをファインチューニングし作成したLow-Rank AdapterのリンクとGenerateっサンプルコード

### Japanese-Alpaca-LoRA-7b DEMOページ(期間限定)  
https://huggingface.co/spaces/kunishou/Japanese-Alapaca-LoRA-7b-DEMO

Temparature : 生成する回答の多様性度合い  
Beams : 生成する回答の候補数  
max_tokens : 生成する回答の長さ  

入力例：  
instruct :   
input :   

### Try the pretrainde model using google colab

<a href="https://colab.research.google.com/github/kunishou/Japanese-Alpaca-LoRA/blob/main/generate_colb.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

### LoRA on Hugging Face
Japanese-Alpaca-LoRA 7b, 13B, 30B (65B Coming Soon!)
https://huggingface.co/kunishou
